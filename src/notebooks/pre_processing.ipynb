{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e281534",
   "metadata": {},
   "source": [
    "# ConfiguraÃ§Ãµes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac744b",
   "metadata": {},
   "source": [
    "## ImportaÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99c20b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb4a6b",
   "metadata": {},
   "source": [
    "## DefiniÃ§Ã£o do Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3271a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08c4b6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'artists', 'duration_ms', 'year', 'acousticness',\n",
       "       'danceability', 'energy', 'instrumentalness', 'speechiness', 'valence',\n",
       "       'popularity', 'explicit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643bd8ab",
   "metadata": {},
   "source": [
    "# PrÃ©-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d368ca4f",
   "metadata": {},
   "source": [
    "## SeleÃ§Ã£o de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76daa568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selecao = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea59beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"year\",\n",
    "    \"popularity\",\n",
    "    \"acousticness\",\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"valence\",\n",
    "    \"explicit\",\n",
    "]\n",
    "\n",
    "features_normalized = [\"acousticness\", \"danceability\", \"energy\", \"valence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5e86e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_selecao.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c98c5",
   "metadata": {},
   "source": [
    "## NormalizaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02a834d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "ðŸ”§ CONSTRUINDO PIPELINE DE NORMALIZAÃ‡ÃƒO\n",
      "==========================================================================================\n",
      "âœ… Scaler criado e treinado\n",
      "   Features: ['acousticness', 'danceability', 'energy', 'valence']\n",
      "   Shape: (169907, 4)\n",
      "\n",
      "   MÃ©dia (deve estar prÃ³xima a 0):\n",
      "acousticness   -1.391753e-16\n",
      "danceability    3.104680e-16\n",
      "energy          1.498811e-16\n",
      "valence         1.927043e-16\n",
      "dtype: float64\n",
      "\n",
      "   Desvio padrÃ£o (deve estar prÃ³ximo a 1):\n",
      "acousticness    1.000003\n",
      "danceability    1.000003\n",
      "energy          1.000003\n",
      "valence         1.000003\n",
      "dtype: float64\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"ðŸ”§ CONSTRUINDO PIPELINE DE NORMALIZAÃ‡ÃƒO\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "scaler_reduced = StandardScaler()\n",
    "scaler_reduced.fit(df_features[features_normalized])\n",
    "\n",
    "df_features_normalized_reduced_scaled = pd.DataFrame(\n",
    "    scaler_reduced.transform(df_features[features_normalized]),\n",
    "    columns=features_normalized,\n",
    ")\n",
    "\n",
    "print(\"âœ… Scaler criado e treinado\")\n",
    "print(f\"   Features: {features_normalized}\")\n",
    "print(f\"   Shape: {df_features_normalized_reduced_scaled.shape}\")\n",
    "print(\"\\n   MÃ©dia (deve estar prÃ³xima a 0):\")\n",
    "print(df_features_normalized_reduced_scaled.mean())\n",
    "print(\"\\n   Desvio padrÃ£o (deve estar prÃ³ximo a 1):\")\n",
    "print(df_features_normalized_reduced_scaled.std())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d526a98",
   "metadata": {},
   "source": [
    "## BinarizaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bd9c7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "ðŸ”„ APLICANDO BINARIZAÃ‡ÃƒO DE POPULARITY\n",
      "==========================================================================================\n",
      "\n",
      "Threshold utilizado: 33\n",
      "\n",
      "ðŸ“Š BinarizaÃ§Ã£o: df_features['popularity']\n",
      "------------------------------------------------------------------------------------------\n",
      "âœ… BinarizaÃ§Ã£o aplicada\n",
      "   â†’ Classe 0 (â‰¤ 33): 84964 (50.01%)\n",
      "   â†’ Classe 1 (> 33): 84943 (49.99%)\n",
      "   â†’ Total: 169907 registros\n",
      "   â†’ Dataframe final: apenas coluna 'is_popular'\n",
      "   â†’ Shape: (169907, 1)\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"ðŸ”„ APLICANDO BINARIZAÃ‡ÃƒO DE POPULARITY\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "POPULARITY_THRESHOLD = 33\n",
    "\n",
    "print(f\"\\nThreshold utilizado: {POPULARITY_THRESHOLD}\")\n",
    "\n",
    "print(\"\\nðŸ“Š BinarizaÃ§Ã£o: df_features['popularity']\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "is_popular = (df_features[\"popularity\"] > POPULARITY_THRESHOLD).astype(int)\n",
    "\n",
    "binary_distribution = is_popular.value_counts().sort_index()\n",
    "binary_pcts = is_popular.value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "print(\"âœ… BinarizaÃ§Ã£o aplicada\")\n",
    "print(\n",
    "    f\"   â†’ Classe 0 (â‰¤ {POPULARITY_THRESHOLD}): {binary_distribution[0]} ({binary_pcts[0]:.2f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"   â†’ Classe 1 (> {POPULARITY_THRESHOLD}): {binary_distribution[1]} ({binary_pcts[1]:.2f}%)\"\n",
    ")\n",
    "print(f\"   â†’ Total: {len(is_popular)} registros\")\n",
    "\n",
    "df_popularity_binary = pd.DataFrame({\"is_popular\": is_popular})\n",
    "\n",
    "print(\"   â†’ Dataframe final: apenas coluna 'is_popular'\")\n",
    "print(f\"   â†’ Shape: {df_popularity_binary.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e85a5e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "ðŸŽµ CRIANDO FEATURES DECADES COM ONE-HOT ENCODING\n",
      "==========================================================================================\n",
      "\n",
      "ðŸ“Š ExtraÃ§Ã£o de dÃ©cadas\n",
      "------------------------------------------------------------------------------------------\n",
      "   DÃ©cadas encontradas no dataset: [np.int64(1920), np.int64(1930), np.int64(1940), np.int64(1950), np.int64(1960), np.int64(1970), np.int64(1980), np.int64(1990), np.int64(2000), np.int64(2010), np.int64(2020)]\n",
      "   Intervalo: 1920 a 2020\n",
      "\n",
      "ðŸ“Œ DÃ©cadas para One-Hot Encoding: [1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010, 2020]\n",
      "\n",
      "âœ… One-Hot Encoding aplicado\n",
      "   Shape: (169907, 11)\n",
      "   Features criadas: ['1920s', '1930s', '1940s', '1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s', '2020s']\n",
      "\n",
      "ðŸ“Š DistribuiÃ§Ã£o de dÃ©cadas:\n",
      "   1920s: 4446 (2.62%)\n",
      "   1930s: 8889 (5.23%)\n",
      "   1940s: 14968 (8.81%)\n",
      "   1950s: 19950 (11.74%)\n",
      "   1960s: 20000 (11.77%)\n",
      "   1970s: 19998 (11.77%)\n",
      "   1980s: 20000 (11.77%)\n",
      "   1990s: 20000 (11.77%)\n",
      "   2000s: 20000 (11.77%)\n",
      "   2010s: 19900 (11.71%)\n",
      "   2020s: 1756 (1.03%)\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"ðŸŽµ CRIANDO FEATURES DECADES COM ONE-HOT ENCODING\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Criar coluna 'decade' a partir de 'year'\n",
    "df_decades = df_features.copy()\n",
    "df_decades[\"decade\"] = (df_decades[\"year\"] // 10 * 10).astype(int)\n",
    "\n",
    "print(\"\\nðŸ“Š ExtraÃ§Ã£o de dÃ©cadas\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"   DÃ©cadas encontradas no dataset: {sorted(df_decades['decade'].unique())}\")\n",
    "print(f\"   Intervalo: {df_decades['decade'].min()} a {df_decades['decade'].max()}\")\n",
    "\n",
    "# Definir todas as dÃ©cadas de 1920 a 2025\n",
    "# 1920-1930, 1930-1940, ..., 2020-2030\n",
    "all_decades = list(range(1920, 2030, 10))\n",
    "\n",
    "print(f\"\\nðŸ“Œ DÃ©cadas para One-Hot Encoding: {all_decades}\")\n",
    "\n",
    "# Criar dataframe com One-Hot Encoding\n",
    "decades_ohe = pd.DataFrame()\n",
    "\n",
    "for decade in all_decades:\n",
    "    decade_label = f\"{decade}s\"\n",
    "    decades_ohe[decade_label] = (\n",
    "        (df_decades[\"decade\"] >= decade) & (df_decades[\"decade\"] < decade + 10)\n",
    "    ).astype(int)\n",
    "\n",
    "print(\"\\nâœ… One-Hot Encoding aplicado\")\n",
    "print(f\"   Shape: {decades_ohe.shape}\")\n",
    "print(f\"   Features criadas: {list(decades_ohe.columns)}\")\n",
    "\n",
    "print(\"\\nðŸ“Š DistribuiÃ§Ã£o de dÃ©cadas:\")\n",
    "for col in decades_ohe.columns:\n",
    "    count = decades_ohe[col].sum()\n",
    "    pct = (count / len(decades_ohe)) * 100\n",
    "    print(f\"   {col}: {int(count)} ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b62c4b7",
   "metadata": {},
   "source": [
    "## Mesclagem de dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbaca327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "ðŸ”— MESCLANDO DATAFRAMES\n",
      "==========================================================================================\n",
      "\n",
      "ðŸ“Š Criando dataframes finais\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”¹ df_selecao_normalized_with_decades: (169907, 23)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   â†’ Todas as colunas originais (exceto year e popularity)\n",
      "   â†’ Features normalizadas: ['acousticness', 'danceability', 'energy', 'valence']\n",
      "   â†’ Coluna binarizada: is_popular\n",
      "   â†’ Features decades (OHE): 11\n",
      "\n",
      "ðŸ”¹ df_features_normalized_with_decades: (169907, 17)\n",
      "   â†’ Features normalizadas: ['acousticness', 'danceability', 'energy', 'valence']\n",
      "   â†’ Coluna binarizada: is_popular\n",
      "   â†’ Coluna explÃ­cita: explicit\n",
      "   â†’ Features decades (OHE): 11\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"ðŸ”— MESCLANDO DATAFRAMES\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(\"\\nðŸ“Š Criando dataframes finais\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "df_temp_full = df.drop([\"year\", \"popularity\"], axis=1).copy()\n",
    "df_temp_full[features_normalized] = df_features_normalized_reduced_scaled[\n",
    "    features_normalized\n",
    "].values\n",
    "\n",
    "df_selecao_normalized_with_decades = pd.concat(\n",
    "    [df_temp_full, df_popularity_binary, decades_ohe], axis=1\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nðŸ”¹ df_selecao_normalized_with_decades: {df_selecao_normalized_with_decades.shape}\"\n",
    ")\n",
    "print(\"   â†’ Todas as colunas originais (exceto year e popularity)\")\n",
    "print(f\"   â†’ Features normalizadas: {features_normalized}\")\n",
    "print(\"   â†’ Coluna binarizada: is_popular\")\n",
    "print(f\"   â†’ Features decades (OHE): {len(decades_ohe.columns)}\")\n",
    "\n",
    "explicit_col = df_features[[\"explicit\"]].reset_index(drop=True)\n",
    "\n",
    "df_features_normalized_with_decades = pd.concat(\n",
    "    [\n",
    "        df_features_normalized_reduced_scaled.reset_index(drop=True),\n",
    "        df_popularity_binary.reset_index(drop=True),\n",
    "        explicit_col,\n",
    "        decades_ohe.reset_index(drop=True)\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ”¹ df_features_normalized_with_decades: {df_features_normalized_with_decades.shape}\")\n",
    "print(f\"   â†’ Features normalizadas: {features_normalized}\")\n",
    "print(\"   â†’ Coluna binarizada: is_popular\")\n",
    "print(\"   â†’ Coluna explÃ­cita: explicit\")\n",
    "print(f\"   â†’ Features decades (OHE): {len(decades_ohe.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30779a2",
   "metadata": {},
   "source": [
    "# Gerar o dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0963241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "ðŸ’¾ EXPORTANDO DATAFRAMES FINAIS\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… selecao_normalized_with_decades.csv\n",
      "   Shape: 169907 linhas Ã— 23 colunas\n",
      "\n",
      "âœ… features_normalized_with_decades.csv\n",
      "   Shape: 169907 linhas Ã— 17 colunas\n",
      "\n",
      "âœ… scaler.joblib\n",
      "   Scaler salvo com as features: ['acousticness', 'danceability', 'energy', 'valence']\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"ðŸ’¾ EXPORTANDO DATAFRAMES FINAIS\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "os.makedirs(\"../datasets\", exist_ok=True)\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "df_selecao_normalized_with_decades.to_csv(\n",
    "    \"../datasets/selecao_normalized_with_decades.csv\", index=False, encoding=\"utf-8\"\n",
    ")\n",
    "print(\"\\nâœ… selecao_normalized_with_decades.csv\")\n",
    "print(\n",
    "    f\"   Shape: {df_selecao_normalized_with_decades.shape[0]} linhas Ã— {df_selecao_normalized_with_decades.shape[1]} colunas\"\n",
    ")\n",
    "\n",
    "df_features_normalized_with_decades.to_csv(\n",
    "    \"../datasets/features_normalized_with_decades.csv\", index=False, encoding=\"utf-8\"\n",
    ")\n",
    "print(\"\\nâœ… features_normalized_with_decades.csv\")\n",
    "print(\n",
    "    f\"   Shape: {df_features_normalized_with_decades.shape[0]} linhas Ã— {df_features_normalized_with_decades.shape[1]} colunas\"\n",
    ")\n",
    "\n",
    "joblib.dump(scaler_reduced, \"../models/scaler.joblib\")\n",
    "print(\"\\nâœ… scaler.joblib\")\n",
    "print(f\"   Scaler salvo com as features: {features_normalized}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1924ff8",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c4ea9",
   "metadata": {},
   "source": [
    "Basicamente, normalizei as 4 features de Ã¡udio (acousticness, danceability, energy, valence) usando StandardScaler pra padronizar os valores.\n",
    "\n",
    "Depois transformei a coluna de popularity em algo binÃ¡rio (is_popular), usando 33 como threshold, valor este obtido na anÃ¡lise exploratÃ³ria.\n",
    "\n",
    "No final ficou com 12 features: as 4 normalizadas + 1 binÃ¡ria de popularity + 1 binÃ¡ria de explicit + 6 features de dÃ©cada (one-hot encoding).\n",
    "\n",
    "Exportei tudo em 3 arquivos: 2 CSVs (um completo com todos os dados, outro sÃ³ com as features) e o scaler em joblib pra usar depois."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotify-music-recomendation-_5l54QgE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
